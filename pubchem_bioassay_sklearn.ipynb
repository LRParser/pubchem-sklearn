{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "\n",
    "PubChem is a site run by the NIH which hosts raw data associated with chemical experiments; here we analyze the data hosted at PubChem for assay 1030, which looks for inhibitors of the protein encoding gene ALDH1A1. You can access the page for this assay [here](https://pubchem.ncbi.nlm.nih.gov/bioassay/1030)\n",
    "\n",
    "## Results ##\n",
    "\n",
    "We use the SMILES string, a common representation for a molecule amongst chemists, to begin the featurization process. Because the length of this string varies, it is normalized in the form of a Morgan Fingerprint; these are then used to train various binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "global_random_state = 42\n",
    "k_fold_splits = 2\n",
    "\n",
    "np.random.seed(global_random_state)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fh = logging.FileHandler('log_sklearn.txt')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "class_weights = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 16:14:30,370 - INFO - Processed index: 10000\n",
      "2017-09-28 16:14:36,023 - INFO - Processed index: 30000\n",
      "2017-09-28 16:14:38,928 - INFO - Processed index: 40000\n",
      "2017-09-28 16:14:41,862 - INFO - Processed index: 50000\n",
      "2017-09-28 16:14:44,916 - INFO - Processed index: 60000\n",
      "2017-09-28 16:14:50,920 - INFO - Processed index: 80000\n",
      "2017-09-28 16:14:53,836 - INFO - Processed index: 90000\n",
      "2017-09-28 16:14:56,839 - INFO - Processed index: 100000\n",
      "2017-09-28 16:14:59,765 - INFO - Processed index: 110000\n",
      "2017-09-28 16:15:02,805 - INFO - Processed index: 120000\n",
      "2017-09-28 16:15:05,925 - INFO - Processed index: 130000\n",
      "2017-09-28 16:15:09,084 - INFO - Processed index: 140000\n",
      "2017-09-28 16:15:12,216 - INFO - Processed index: 150000\n",
      "2017-09-28 16:15:18,478 - INFO - Processed index: 170000\n",
      "2017-09-28 16:15:30,787 - INFO - Processed index: 210000\n",
      "2017-09-28 16:15:34,424 - INFO - Processed index: 220000\n",
      "2017-09-28 16:15:34,908 - INFO - Undersampling\n",
      "2017-09-28 16:15:35,011 - INFO - Compute classes statistics ...\n",
      "2017-09-28 16:15:35,013 - DEBUG - The number of classes is 2\n",
      "2017-09-28 16:15:35,015 - DEBUG - Shall we raise a warning: False\n",
      "2017-09-28 16:15:35,035 - INFO - 2 classes detected: Counter({0: 148299, 1: 16111})\n",
      "2017-09-28 16:15:35,744 - INFO - Under-sampling performed: Counter({1: 16111, 0: 16111})\n"
     ]
    }
   ],
   "source": [
    "# Load assay info. Note: This CSV was obtained from PubChem bioassay aka PCBA, via searching for AID 1030 \n",
    "# and downloading the datatable\n",
    "\n",
    "ba_df = pd.read_csv(\"AID_1030_datatable_all.csv\")\n",
    "\n",
    "# Load compound info\n",
    "cs_df = pd.read_csv(\"AID_1030_compound_smiles.csv\",sep='\\t',header=0)\n",
    "\n",
    "# Merge the two\n",
    "full_df = ba_df.merge(cs_df,on='PUBCHEM_CID')\n",
    "\n",
    "# Cleanup the compound ID column\n",
    "full_df[\"PUBCHEM_CID\"] = full_df[\"PUBCHEM_CID\"].astype(int)\n",
    "\n",
    "# Delete CID 3246048, which fails featurization\n",
    "full_df = full_df[full_df[\"PUBCHEM_CID\"] != 3246048]\n",
    "\n",
    "# Delete all inconclusive results\n",
    "full_df = full_df[full_df[\"PUBCHEM_ACTIVITY_OUTCOME\"] != \"Inconclusive\"]\n",
    "\n",
    "# Delete CID 3246048, which fails featurization\n",
    "\n",
    "compound_ids = list()\n",
    "smiles_list = list()\n",
    "fingerprints = list()\n",
    "activities = list()\n",
    "\n",
    "#fingerprint_df = \n",
    "\n",
    "for index, row in full_df.iterrows() :\n",
    "    cid = row[\"PUBCHEM_CID\"]\n",
    "    smiles_string = row[\"Smiles\"]\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    is_active = row[\"PUBCHEM_ACTIVITY_OUTCOME\"] == \"Active\"\n",
    "    if mol is None:\n",
    "        logger.info(\"Molecule failed featurization\")\n",
    "        logger.info(index)\n",
    "    else: \n",
    "        fingerprint = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol,2,nBits=2048,useChirality=False,\n",
    "                                                                     useBondTypes=False,useFeatures=False)\n",
    "        \n",
    "        # From RDKit documentation\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fingerprint, arr)\n",
    "        fingerprint = arr\n",
    "        \n",
    "        compound_ids.append(cid)\n",
    "        smiles_list.append(smiles_string)\n",
    "        fingerprints.append(fingerprint)\n",
    "        activities.append(is_active)\n",
    "    \n",
    "    if index % 10000 == 0:\n",
    "        logger.info(\"Processed index: {0}\".format(index))\n",
    "\n",
    "fingerprints = np.array(fingerprints)\n",
    "activities = np.array(activities,dtype=int)\n",
    "        \n",
    "logger.info(\"Undersampling\")\n",
    "\n",
    "rus = RandomUnderSampler(random_state=global_random_state)\n",
    "X, y = rus.fit_sample(fingerprints, activities)\n",
    "\n",
    "# Pickle the data to save time in the future\n",
    "with open('data.classification.undersampled.pickle', 'wb') as f:\n",
    "    pickle.dump((X,y), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from collections import Counter\n",
    "\n",
    "k_fold_splits = 2\n",
    "global_random_state = 42\n",
    "\n",
    "with open('data.classification.undersampled.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    (X, y) = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is: 32222\n",
      "Number of training samples is: 16110\n",
      "Number of test samples is: 16112\n",
      "Number of training samples is: 16112\n",
      "Number of test samples is: 16110\n",
      "2017-09-28 16:15:41,859 - INFO - Average roc_auc score of 2 folds is: 0.4997517224247154\n",
      "2017-09-28 16:15:41,860 - INFO - Average elapsed prediction time over 2 folds in s is: 0.02162623405456543\n"
     ]
    }
   ],
   "source": [
    "# First, let's look at the performance of a Dummy Classifier\n",
    "\n",
    "# What is the performance of a dummy classifier on the test set?\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('data.classification.undersampled.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    (X, y) = pickle.load(f)\n",
    "\n",
    "print(\"Number of samples is: {}\".format(len(X)))\n",
    "    \n",
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True,random_state=global_random_state)\n",
    "\n",
    "roc_auc_avg = 0\n",
    "avg_predict_time = 0\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    print(\"Number of training samples is: {}\".format(len(X_train)))\n",
    "    print(\"Number of test samples is: {}\".format(len(X_test)))\n",
    "\n",
    "    classifier = DummyClassifier(random_state=global_random_state)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    start = time.time()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    avg_predict_time = avg_predict_time + elapsed\n",
    "    #logger.info(classification_report(y_test, y_pred))\n",
    "    # What is the AUC-ROC score?\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "avg_predict_time = avg_predict_time / k_fold_splits\n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.info(\"Average roc_auc score of {} folds is: {}\".format(k_fold_splits, roc_auc_avg))\n",
    "logger.info(\"Average elapsed prediction time over {} folds in s is: {}\".format(k_fold_splits, avg_predict_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 16:16:04,165 - INFO - Average roc_auc score of 2 folds is: 0.6647324100631397\n",
      "2017-09-28 16:16:07,042 - INFO - Average elapsed prediction time over 2 folds in s is: 3.502115488052368\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True, random_state=global_random_state)\n",
    "\n",
    "roc_auc_avg = 0\n",
    "avg_predict_time = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = DecisionTreeClassifier(random_state=global_random_state,class_weight=class_weights)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    start = time.time()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    avg_predict_time = avg_predict_time + elapsed\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    #logger.info(\"Computed roc_auc score of: {}\".format(auc))\n",
    "    #logger.info(classification_report(y_test, y_pred))\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.info(\"Average roc_auc score of {} folds is: {}\".format(k_fold_splits, roc_auc_avg))\n",
    "logger.info(\"Average elapsed prediction time over {} folds in s is: {}\".format(k_fold_splits, avg_predict_time))\n",
    "\n",
    "# Note: As comparison, there is a mean test ROC_AUC calculated in MoleculeNet for PCBA-128 dataset\n",
    "# of .781 using a logistic regression model\n",
    "# That however applies to a different task (multiclass prediction across 128 bioassays simultaneously vs binary classification here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 16:17:51,513 - INFO - Average roc_auc score is: 0.7425673798309413\n",
      "2017-09-28 16:17:51,625 - INFO - Average elapsed prediction time over 2 folds in s is: 4.380889177322388\n"
     ]
    }
   ],
   "source": [
    "# Let's try using a Random forest\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True,random_state=global_random_state)\n",
    "\n",
    "roc_auc_avg = 0\n",
    "avg_predict_time = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=global_random_state, n_jobs=-1)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    start = time.time()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    avg_predict_time = avg_predict_time + elapsed\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    #logger.info(\"Computed roc_auc score of: {}\".format(auc))\n",
    "    #logger.info(classification_report(y_test, y_pred))\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.info(\"Average roc_auc score is: {}\".format(roc_auc_avg))\n",
    "logger.info(\"Average elapsed prediction time over {} folds in s is: {}\".format(k_fold_splits, avg_predict_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 16:17:58,592 - INFO - Average roc_auc score is: 0.697101308068844\n",
      "2017-09-28 16:17:58,593 - INFO - Average elapsed prediction time over 2 folds in s is: 0.23391437530517578\n"
     ]
    }
   ],
   "source": [
    "# Let's try using a Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True,random_state=global_random_state)\n",
    "\n",
    "roc_auc_avg = 0\n",
    "avg_predict_time = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = LogisticRegression(random_state=global_random_state, n_jobs=-1)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    start = time.time()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    elapsed = time.time() - start\n",
    "    avg_predict_time = avg_predict_time + elapsed\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.info(\"Average roc_auc score is: {}\".format(roc_auc_avg))\n",
    "logger.info(\"Average elapsed prediction time over {} folds in s is: {}\".format(k_fold_splits, avg_predict_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute '_best_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c0f2d03f001f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrandomized_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_random_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrandomized_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best found score of: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomized_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best found model: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomized_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute '_best_score'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, random_state=global_random_state, n_jobs=-1)\n",
    "param_dist = {\"n_estimators\": [10, 100, 1000],\n",
    "              \"min_samples_split\": [1,5, 20, 50],\n",
    "              \"min_samples_leaf\": [1,5, 20, 50],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "randomized_search = RandomizedSearchCV(estimator,param_dist, scoring=\"roc_auc\",n_jobs=-1, random_state=global_random_state)\n",
    "randomized_search.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found score of: 0.7287595195687173\n",
      "Best found model: RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=5,\n",
      "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best found score of: {}\".format(randomized_search.best_score_))\n",
    "print(\"Best found model: {}\".format(randomized_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the predictions that the best-performing model makes on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try to improve the Random Forest via hyperparameter search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pubchem-sklearn]",
   "language": "python",
   "name": "conda-env-pubchem-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
