{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "\n",
    "PubChem is a site run by the NIH which hosts raw data associated with chemical experiments; here we analyze the data hosted at PubChem for assay 1030, which looks for inhibitors of the protein encoding gene ALDH1A1. You can access the page for this assay [here](https://pubchem.ncbi.nlm.nih.gov/bioassay/1030)\n",
    "\n",
    "## Results ##\n",
    "\n",
    "We use the SMILES string, a common representation for a molecule amongst chemists, to begin the featurization process. Because the length of this string varies, it is normalized in the form of a Morgan Fingerprint; these are then used to train various binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exploratory data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "global_random_state = 42\n",
    "k_fold_splits = 2\n",
    "\n",
    "np.random.seed(global_random_state)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fh = logging.FileHandler('log_sklearn.txt')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "class_weights = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-24 10:47:07,188 - INFO - Processed index: 0\n",
      "2017-09-24 10:47:14,685 - INFO - Processed index: 10000\n",
      "2017-09-24 10:47:21,884 - INFO - Processed index: 20000\n",
      "2017-09-24 10:47:29,346 - INFO - Processed index: 30000\n",
      "2017-09-24 10:47:36,966 - INFO - Processed index: 40000\n",
      "2017-09-24 10:47:43,923 - INFO - Processed index: 50000\n",
      "2017-09-24 10:47:50,960 - INFO - Processed index: 60000\n",
      "2017-09-24 10:47:57,810 - INFO - Processed index: 70000\n",
      "2017-09-24 10:48:05,306 - INFO - Processed index: 80000\n",
      "2017-09-24 10:48:13,079 - INFO - Processed index: 90000\n",
      "2017-09-24 10:48:20,616 - INFO - Processed index: 100000\n",
      "2017-09-24 10:48:27,684 - INFO - Processed index: 110000\n",
      "2017-09-24 10:48:35,354 - INFO - Processed index: 120000\n",
      "2017-09-24 10:48:44,147 - INFO - Processed index: 130000\n",
      "2017-09-24 10:48:52,683 - INFO - Processed index: 140000\n",
      "2017-09-24 10:49:00,565 - INFO - Processed index: 150000\n",
      "2017-09-24 10:49:08,363 - INFO - Processed index: 160000\n",
      "2017-09-24 10:49:16,213 - INFO - Processed index: 170000\n",
      "2017-09-24 10:49:23,407 - INFO - Processed index: 180000\n",
      "2017-09-24 10:49:30,430 - INFO - Processed index: 190000\n",
      "2017-09-24 10:49:38,073 - INFO - Processed index: 200000\n",
      "2017-09-24 10:49:46,485 - INFO - Processed index: 210000\n",
      "2017-09-24 10:49:53,336 - INFO - Molecule failed featurization\n",
      "2017-09-24 10:49:53,338 - INFO - 218052\n",
      "2017-09-24 10:49:54,960 - INFO - Processed index: 220000\n",
      "2017-09-24 10:49:56,860 - INFO - Sampling\n",
      "2017-09-24 10:49:57,260 - INFO - Compute classes statistics ...\n",
      "2017-09-24 10:49:57,266 - DEBUG - The number of classes is 2\n",
      "2017-09-24 10:49:57,271 - DEBUG - Shall we raise a warning: False\n",
      "2017-09-24 10:49:57,325 - INFO - 2 classes detected: Counter({0: 204253, 1: 16111})\n",
      "2017-09-24 10:49:59,254 - INFO - Under-sampling performed: Counter({1: 16111, 0: 16111})\n",
      "2017-09-24 10:49:59,255 - INFO - Processed all, pickling\n"
     ]
    }
   ],
   "source": [
    "# Load assay info. Note: This CSV was obtained from PubChem bioassay aka PCBA, via searching for AID 1030 \n",
    "# and downloading the datatable\n",
    "\n",
    "ba_df = pd.read_csv(\"AID_1030_datatable_all.csv\")\n",
    "\n",
    "# Load compound info\n",
    "cs_df = pd.read_csv(\"AID_1030_compound_smiles.csv\",sep='\\t',header=0)\n",
    "\n",
    "# Merge the two\n",
    "full_df = ba_df.merge(cs_df,on='PUBCHEM_CID')\n",
    "\n",
    "# Cleanup the compound ID column\n",
    "full_df[\"PUBCHEM_CID\"] = full_df[\"PUBCHEM_CID\"].astype(int)\n",
    "\n",
    "# Delete CID 3246048, which fails featurization\n",
    "\n",
    "compound_ids = list()\n",
    "smiles_list = list()\n",
    "fingerprints = list()\n",
    "activities = list()\n",
    "\n",
    "#fingerprint_df = \n",
    "\n",
    "for index, row in full_df.iterrows() :\n",
    "    cid = row[\"PUBCHEM_CID\"]\n",
    "    smiles_string = row[\"Smiles\"]\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    is_active = row[\"PUBCHEM_ACTIVITY_OUTCOME\"] == \"Active\"\n",
    "    if mol is None:\n",
    "        logger.info(\"Molecule failed featurization\")\n",
    "        logger.info(index)\n",
    "    else: \n",
    "        fingerprint = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol,2,nBits=2048,useChirality=False,\n",
    "                                                                     useBondTypes=False,useFeatures=False)\n",
    "        \n",
    "        # From RDKit documentation\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fingerprint, arr)\n",
    "        fingerprint = arr\n",
    "        \n",
    "        compound_ids.append(cid)\n",
    "        smiles_list.append(smiles_string)\n",
    "        fingerprints.append(fingerprint)\n",
    "        activities.append(is_active)\n",
    "    \n",
    "    if index % 10000 == 0:\n",
    "        logger.info(\"Processed index: {0}\".format(index))\n",
    "\n",
    "fingerprints = np.array(fingerprints)\n",
    "activities = np.array(activities,dtype=int)\n",
    "        \n",
    "logger.info(\"Sampling\")\n",
    "\n",
    "rus = RandomUnderSampler(random_state=global_random_state)\n",
    "X, y = rus.fit_sample(fingerprints, activities)\n",
    "\n",
    "logger.info(\"Processed all, pickling\")\n",
    "\n",
    "#compound_ids_and_features = (compound_ids, smiles_list, fingerprints, activities)\n",
    "\n",
    "# Pickle the data to save time in the future\n",
    "with open('data.classification.undersampled.pickle', 'wb') as f:\n",
    "    pickle.dump((X,y), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from collections import Counter\n",
    "\n",
    "global_random_state = 42\n",
    "\n",
    "with open('data.classification.undersampled.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    (X, y) = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-24 10:50:17,334 - INFO - Computed roc_auc score of: 0.6342477656405163\n",
      "2017-09-24 10:50:17,340 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.63      0.63      8056\n",
      "          1       0.63      0.64      0.63      8056\n",
      "\n",
      "avg / total       0.63      0.63      0.63     16112\n",
      "\n",
      "2017-09-24 10:50:30,245 - INFO - Computed roc_auc score of: 0.6350093109869646\n",
      "2017-09-24 10:50:30,250 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.62      0.63      8055\n",
      "          1       0.63      0.65      0.64      8055\n",
      "\n",
      "avg / total       0.64      0.64      0.63     16110\n",
      "\n",
      "2017-09-24 10:50:30,251 - DEBUG - Average roc_auc score is: 0.6346285383137404\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True, random_state=global_random_state)\n",
    "\n",
    "roc_auc_avg = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = DecisionTreeClassifier(random_state=global_random_state,class_weight=class_weights)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    logger.info(\"Computed roc_auc score of: {}\".format(auc))\n",
    "    logger.info(classification_report(y_test, y_pred))\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.debug(\"Average roc_auc score is: {}\".format(roc_auc_avg))\n",
    "\n",
    "\n",
    "# Note: Unfortunately it's not directly comparable to ROC_AUC calculated in MoleculeNet at: https://arxiv.org/pdf/1703.00564.pdf \n",
    "# This is because MoleculeNet looks at a different metric (roc_auc) and also a different task (multiclass prediction across 128 bioassays simultaneously vs binary classification here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-24 11:02:00,506 - INFO - Computed roc_auc score of: 0.6899205561072493\n",
      "2017-09-24 11:02:00,511 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.71      0.70      8056\n",
      "          1       0.70      0.67      0.68      8056\n",
      "\n",
      "avg / total       0.69      0.69      0.69     16112\n",
      "\n",
      "2017-09-24 11:16:08,598 - INFO - Computed roc_auc score of: 0.6929857231533209\n",
      "2017-09-24 11:16:08,602 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.67      0.69      8055\n",
      "          1       0.69      0.71      0.70      8055\n",
      "\n",
      "avg / total       0.69      0.69      0.69     16110\n",
      "\n",
      "2017-09-24 11:16:08,603 - DEBUG - Average roc_auc score is: 0.6914531396302851\n"
     ]
    }
   ],
   "source": [
    "# Does an MLP classifier help?\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True,random_state=global_random_state)\n",
    "\n",
    "roc_auc_avg = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = MLPClassifier(random_state=global_random_state)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    logger.info(\"Computed roc_auc score of: {}\".format(auc))\n",
    "    logger.info(classification_report(y_test, y_pred))\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.debug(\"Average roc_auc score is: {}\".format(roc_auc_avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-24 11:16:15,693 - INFO - Computed roc_auc score of: 0.7089126117179742\n",
      "2017-09-24 11:16:15,697 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.74      0.72      8056\n",
      "          1       0.72      0.68      0.70      8056\n",
      "\n",
      "avg / total       0.71      0.71      0.71     16112\n",
      "\n",
      "2017-09-24 11:16:23,796 - INFO - Computed roc_auc score of: 0.7093109869646183\n",
      "2017-09-24 11:16:23,801 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.72      0.71      8055\n",
      "          1       0.72      0.69      0.70      8055\n",
      "\n",
      "avg / total       0.71      0.71      0.71     16110\n",
      "\n",
      "2017-09-24 11:16:23,802 - INFO - Average roc_auc score is: 0.7091117993412962\n"
     ]
    }
   ],
   "source": [
    "# Let's try using a Random forest\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True,random_state=global_random_state)\n",
    "\n",
    "roc_auc_avg = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=global_random_state, n_jobs=-1)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    logger.info(\"Computed roc_auc score of: {}\".format(auc))\n",
    "    logger.info(classification_report(y_test, y_pred))\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.info(\"Average roc_auc score is: {}\".format(roc_auc_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-24 11:16:24,199 - INFO - tpe_transform took 0.047793 seconds\n",
      "2017-09-24 11:16:24,200 - INFO - TPE using 0 trials\n",
      "2017-09-24 11:21:24,647 - INFO - tpe_transform took 0.045656 seconds\n",
      "2017-09-24 11:21:24,648 - INFO - TPE using 1/1 trials with best loss inf\n",
      "2017-09-24 11:26:25,001 - INFO - tpe_transform took 0.046115 seconds\n",
      "2017-09-24 11:26:25,002 - INFO - TPE using 2/2 trials with best loss inf\n",
      "2017-09-24 11:28:28,659 - INFO - tpe_transform took 0.045682 seconds\n",
      "2017-09-24 11:28:28,661 - INFO - TPE using 3/3 trials with best loss 0.319129\n",
      "2017-09-24 11:32:39,734 - INFO - tpe_transform took 0.129502 seconds\n",
      "2017-09-24 11:32:39,735 - INFO - TPE using 4/4 trials with best loss 0.319129\n",
      "2017-09-24 11:37:40,121 - INFO - tpe_transform took 0.043525 seconds\n",
      "2017-09-24 11:37:40,123 - INFO - TPE using 5/5 trials with best loss 0.319129\n",
      "2017-09-24 11:42:40,576 - INFO - tpe_transform took 0.046590 seconds\n",
      "2017-09-24 11:42:40,577 - INFO - TPE using 6/6 trials with best loss 0.319129\n",
      "2017-09-24 11:42:46,321 - INFO - tpe_transform took 0.046814 seconds\n",
      "2017-09-24 11:42:46,323 - INFO - TPE using 7/7 trials with best loss 0.319129\n",
      "2017-09-24 11:43:06,088 - INFO - tpe_transform took 0.046755 seconds\n",
      "2017-09-24 11:43:06,090 - INFO - TPE using 8/8 trials with best loss 0.319129\n",
      "2017-09-24 11:46:29,785 - INFO - tpe_transform took 0.044329 seconds\n",
      "2017-09-24 11:46:29,787 - INFO - TPE using 9/9 trials with best loss 0.319129\n",
      "2017-09-24 11:53:57,528 - INFO - tpe_transform took 0.048498 seconds\n",
      "2017-09-24 11:53:57,530 - INFO - TPE using 0 trials\n",
      "2017-09-24 11:54:47,740 - INFO - tpe_transform took 0.045480 seconds\n",
      "2017-09-24 11:54:47,742 - INFO - TPE using 1/1 trials with best loss 0.316350\n",
      "2017-09-24 11:59:48,141 - INFO - tpe_transform took 0.046877 seconds\n",
      "2017-09-24 11:59:48,143 - INFO - TPE using 2/2 trials with best loss 0.316350\n",
      "2017-09-24 12:00:10,025 - INFO - tpe_transform took 0.047770 seconds\n",
      "2017-09-24 12:00:10,027 - INFO - TPE using 3/3 trials with best loss 0.316350\n",
      "2017-09-24 12:05:10,327 - INFO - tpe_transform took 0.047304 seconds\n",
      "2017-09-24 12:05:10,329 - INFO - TPE using 4/4 trials with best loss 0.316350\n",
      "2017-09-24 12:10:10,793 - INFO - tpe_transform took 0.046279 seconds\n",
      "2017-09-24 12:10:10,795 - INFO - TPE using 5/5 trials with best loss 0.316350\n",
      "2017-09-24 12:10:12,957 - INFO - tpe_transform took 0.135500 seconds\n",
      "2017-09-24 12:10:12,958 - INFO - TPE using 6/6 trials with best loss 0.316350\n",
      "2017-09-24 12:14:00,796 - INFO - tpe_transform took 0.046082 seconds\n",
      "2017-09-24 12:14:00,798 - INFO - TPE using 7/7 trials with best loss 0.316350\n",
      "2017-09-24 12:14:13,990 - INFO - tpe_transform took 0.045524 seconds\n",
      "2017-09-24 12:14:13,991 - INFO - TPE using 8/8 trials with best loss 0.296665\n",
      "2017-09-24 12:18:33,680 - INFO - tpe_transform took 0.045655 seconds\n",
      "2017-09-24 12:18:33,681 - INFO - TPE using 9/9 trials with best loss 0.296665\n",
      "2017-09-24 12:22:51,958 - INFO - 0.71337220237\n",
      "2017-09-24 12:22:51,960 - INFO - {'learner': RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=72, n_jobs=1, oob_score=False, random_state=3,\n",
      "            verbose=False, warm_start=False), 'preprocs': (MinMaxScaler(copy=True, feature_range=(-1.0, 1.0)),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "# Let's try using a hyperparameter tuning package\n",
    "from hpsklearn import HyperoptEstimator, any_classifier\n",
    "from hyperopt import tpe\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=global_random_state)\n",
    "\n",
    "estim = HyperoptEstimator( classifier=any_classifier('clf'),  \n",
    "                            algo=tpe.suggest, trial_timeout=300)\n",
    "\n",
    "# Search the space of classifiers and preprocessing steps and their\n",
    "# respective hyperparameters in sklearn to fit a model to the data\n",
    "estim.fit( X_train, y_train )\n",
    "\n",
    "# Make a prediction using the optimized model\n",
    "test_label = estim.predict( X_test )\n",
    "\n",
    "# Report the accuracy of the classifier on a given set of data\n",
    "score = estim.score( X_test, test_label )\n",
    "\n",
    "# Return instances of the classifier and preprocessing steps\n",
    "model = estim.best_model()\n",
    "\n",
    "estim.fit( X_train, y_train )\n",
    "\n",
    "logger.info(estim.score(X_test, y_test))\n",
    "logger.info(estim.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-24 13:49:21,987 - INFO - Computed roc_auc score of: 0.7023957298907646\n",
      "2017-09-24 13:49:21,992 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.74      0.71      8056\n",
      "          1       0.72      0.66      0.69      8056\n",
      "\n",
      "avg / total       0.70      0.70      0.70     16112\n",
      "\n",
      "2017-09-24 13:49:35,778 - INFO - Computed roc_auc score of: 0.706455617628802\n",
      "2017-09-24 13:49:35,782 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.74      0.72      8055\n",
      "          1       0.72      0.67      0.70      8055\n",
      "\n",
      "avg / total       0.71      0.71      0.71     16110\n",
      "\n",
      "2017-09-24 13:49:35,783 - INFO - Average roc_auc score is: 1.0589815734304313\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the found model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(copy=True, feature_range=(-1.0, 1.0))\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=72, n_jobs=1, oob_score=False, random_state=3,\n",
    "            verbose=False, warm_start=False)    \n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)\n",
    "    logger.info(\"Computed roc_auc score of: {}\".format(auc))\n",
    "    logger.info(classification_report(y_test, y_pred))\n",
    "    roc_auc_avg = roc_auc_avg + auc\n",
    "    \n",
    "roc_auc_avg = roc_auc_avg / k_fold_splits\n",
    "logger.info(\"Average roc_auc score is: {}\".format(roc_auc_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pubchem-sklearn]",
   "language": "python",
   "name": "conda-env-pubchem-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
