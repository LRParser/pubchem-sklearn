{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "\n",
    "PubChem is a site run by the NIH which hosts raw data associated with chemical experiments; here we analyze the data hosted at PubChem for assay 1030, which looks for inhibitors of the protein encoding gene ALDH1A1. You can access the page for this assay [here](https://pubchem.ncbi.nlm.nih.gov/bioassay/1030)\n",
    "\n",
    "## Results ##\n",
    "\n",
    "We use the SMILES string, a common representation for a molecule amongst chemists, to begin the featurization process. Because the length of this string varies, it is normalized in the form of a Morgan Fingerprint; these are then used to train various DNN-based classifiers in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exploratory data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "global_random_state = 42\n",
    "\n",
    "np.random.seed(global_random_state)\n",
    "\n",
    "\n",
    "active_pct = 0.073125471\n",
    "inactive_pct = 1 - active_pct\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fh = logging.FileHandler('log_dnn.txt')\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16110/16110 [==============================] - 4s - loss: 0.6531 - acc: 0.6145     \n",
      "Epoch 2/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.5821 - acc: 0.6999     \n",
      "Epoch 3/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.5444 - acc: 0.7316     \n",
      "Epoch 4/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.5151 - acc: 0.7520     \n",
      "Epoch 5/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.4842 - acc: 0.7714     \n",
      "Epoch 6/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.4561 - acc: 0.7910     \n",
      "Epoch 7/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.4269 - acc: 0.8094     \n",
      "Epoch 8/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.3972 - acc: 0.8263     \n",
      "Epoch 9/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.3642 - acc: 0.8453     \n",
      "Epoch 10/10\n",
      "16110/16110 [==============================] - 0s - loss: 0.3379 - acc: 0.8590     \n",
      "14400/16112 [=========================>....] - ETA: 0s2017-09-24 14:23:31,958 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.65      0.66      8056\n",
      "          1       0.66      0.67      0.67      8056\n",
      "\n",
      "avg / total       0.66      0.66      0.66     16112\n",
      "\n",
      "Epoch 1/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.6530 - acc: 0.6100     \n",
      "Epoch 2/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.5836 - acc: 0.6976     \n",
      "Epoch 3/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.5488 - acc: 0.7251     \n",
      "Epoch 4/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.5179 - acc: 0.7483     \n",
      "Epoch 5/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.4900 - acc: 0.7659     \n",
      "Epoch 6/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.4565 - acc: 0.7884     \n",
      "Epoch 7/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.4259 - acc: 0.8067     \n",
      "Epoch 8/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.3918 - acc: 0.8268     \n",
      "Epoch 9/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.3600 - acc: 0.8454     \n",
      "Epoch 10/10\n",
      "16112/16112 [==============================] - 0s - loss: 0.3300 - acc: 0.8597     \n",
      "14200/16110 [=========================>....] - ETA: 0s2017-09-24 14:23:40,893 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.66      0.67      8055\n",
      "          1       0.67      0.69      0.68      8055\n",
      "\n",
      "avg / total       0.68      0.68      0.68     16110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What about a deep neural network?\n",
    "# Sample code from: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import pickle\n",
    "\n",
    "k_fold_splits = 2\n",
    "global_random_state = 42\n",
    "\n",
    "with open('data.classification.undersampled.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    (X, y) = pickle.load(f)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
    "\n",
    "    \n",
    "def create_model() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=2048, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True,random_state=global_random_state)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=1)\n",
    "    classifier.fit(X_train,y_train,class_weight=class_weights)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    logger.info(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-24 14:23:40,921 - INFO - Trying a larger network\n",
      "Epoch 1/10\n",
      "16110/16110 [==============================] - 2s - loss: 0.6333 - acc: 0.6379     \n",
      "Epoch 2/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.4921 - acc: 0.7657     \n",
      "Epoch 3/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.2921 - acc: 0.8765     \n",
      "Epoch 4/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.1443 - acc: 0.9438     \n",
      "Epoch 5/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.0834 - acc: 0.9712     \n",
      "Epoch 6/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.0478 - acc: 0.9834     \n",
      "Epoch 7/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.0501 - acc: 0.9843     \n",
      "Epoch 8/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.0277 - acc: 0.9909     \n",
      "Epoch 9/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.0217 - acc: 0.9937     \n",
      "Epoch 10/10\n",
      "16110/16110 [==============================] - 1s - loss: 0.0173 - acc: 0.9944     \n",
      "15800/16112 [============================>.] - ETA: 0s2017-09-24 14:23:57,073 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.71      0.69      8056\n",
      "          1       0.69      0.66      0.67      8056\n",
      "\n",
      "avg / total       0.68      0.68      0.68     16112\n",
      "\n",
      "Epoch 1/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.6331 - acc: 0.6411     \n",
      "Epoch 2/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.4932 - acc: 0.7649     \n",
      "Epoch 3/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.2869 - acc: 0.8761     \n",
      "Epoch 4/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.1288 - acc: 0.9507     \n",
      "Epoch 5/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.0790 - acc: 0.9719     \n",
      "Epoch 6/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.0521 - acc: 0.9827     \n",
      "Epoch 7/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.0391 - acc: 0.9872     \n",
      "Epoch 8/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.0235 - acc: 0.9923     \n",
      "Epoch 9/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.0168 - acc: 0.9946     \n",
      "Epoch 10/10\n",
      "16112/16112 [==============================] - 1s - loss: 0.0213 - acc: 0.9937     \n",
      "15700/16110 [============================>.] - ETA: 0s2017-09-24 14:24:12,859 - INFO -              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.73      0.70      8055\n",
      "          1       0.71      0.64      0.67      8055\n",
      "\n",
      "avg / total       0.69      0.69      0.69     16110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try using DNN on the full non-sampled dataset, but with class_weight set and larger network. It didn't work\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "k_fold_splits = 2\n",
    "global_random_state = 42\n",
    "\n",
    "logger.info(\"Trying a larger network\")\n",
    "\n",
    "def create_model() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=2048, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_fold_splits,shuffle=True,random_state=global_random_state)\n",
    "\n",
    "for train_index, test_index in skf.split(X,y) :\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    classifier = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=1)\n",
    "    classifier.fit(X_train,y_train,class_weight=class_weights)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    logger.info(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pubchem-sklearn]",
   "language": "python",
   "name": "conda-env-pubchem-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
