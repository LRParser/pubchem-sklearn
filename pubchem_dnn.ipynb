{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "\n",
    "PubChem is a site run by the NIH which hosts raw data associated with chemical experiments; here we analyze the data hosted at PubChem for assay 1030, which looks for inhibitors of the protein encoding gene ALDH1A1. You can access the page for this assay [here](https://pubchem.ncbi.nlm.nih.gov/bioassay/1030)\n",
    "\n",
    "## Results ##\n",
    "\n",
    "We use the SMILES string, a common representation for a molecule amongst chemists, to begin the featurization process. Because the length of this string varies, it is normalized in the form of a Morgan Fingerprint; these are then used to train various binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exploratory data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "global_random_state = 42\n",
    "k_fold_splits = 5\n",
    "\n",
    "np.random.seed(global_random_state)\n",
    "\n",
    "\n",
    "active_pct = 0.073125471\n",
    "inactive_pct = 1 - active_pct\n",
    "\n",
    "# We set the inactive to have the weight of the active, and vice versa, to account for imbalance\n",
    "class_weights = { 0: active_pct, 1: inactive_pct }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.backend.backend())\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about a deep neural network?\n",
    "# Sample code from: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "\n",
    "k_fold_splits = 2\n",
    "global_random_state = 42\n",
    "\n",
    "with open('data.classification.undersampled.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    (X, y) = pickle.load(f)\n",
    "\n",
    "def create_model() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=2048, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=3, batch_size=1, verbose=1)\n",
    "results = cross_val_score(model, X, y, cv=k_fold_splits)\n",
    "print(results.mean())\n",
    "\n",
    "y_pred = cross_val_predict(classifier, X, y, cv=k_fold_splits)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_on_batch(X_test)\n",
    "y_pred_binarized = y_pred[0:] > .5\n",
    "print(classification_report(y_test, y_pred_binarized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What about a larger network size?\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=2048, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[metrics.accuracy])\n",
    "\n",
    "model.fit(X_train, y_train_, epochs=10, batch_size=1)\n",
    "\n",
    "score = model.evaluate(X_test, y_test_binary)\n",
    "\n",
    "print(\"\\n Loss on test set is: {0}\".format(score))\n",
    "\n",
    "# let's save it for future experimentation\n",
    "model.save(\"pcba_1030_large_nn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_large = load_model(\"pcba_1030_large_nn.h5\")\n",
    "y_pred = model_large.predict_on_batch(X_test)\n",
    "y_pred_binarized = y_pred[0:] > .5\n",
    "print(classification_report(y_test, y_pred_binarized))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pubchem-sklearn]",
   "language": "python",
   "name": "conda-env-pubchem-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
